{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸­æ–‡tour(ä¸€) quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨pipeline()ä¼ å…¥éœ€è¦å®Œæˆçš„ä»»åŠ¡å³å¯: 'feature-extraction', 'text-classification', 'token-classification', 'question-answering', 'table-question-answering', 'fill-mask', 'summarization', 'translation', 'text2text-generation', 'text-generation', 'zero-shot-classification', 'conversational', 'image-classification', 'translation_XX_to_YY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997795224189758}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier('We are very happy to show you the ğŸ¤— Transformers library.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "# ä¹Ÿå¯ä»¥ç”¨åœ¨ä¸€é•¿ä¸²çš„å¥å­ä¸Šé¢\n",
    "results = classifier([\"We are very happy to show you the ğŸ¤— Transformers library.\",\n",
    "           \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "     print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'i heard a sin from above. They began to pray for him and then their prayers became violent.\\n\\nWhen they heard that sin was happening to their family they fled the area, leaving the children behind.\\n\\nThe police discovered the child in'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"i heard a sin from above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.7977770566940308}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿™é‡Œçœ‹åˆ°æ™®é€šåˆ†ç±»å™¨å¯¹ä¸­æ–‡ä¸æ˜¯å¾ˆæ•æ„Ÿ\n",
    "classifier('ä½ å¤ªå¥½äº†ï¼')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ä¸ªåˆ†ç±»æ¨¡å‹çš„pipelineé»˜è®¤ä¸ºdistilbert-base-uncased-finetuned-sst-2-englishï¼Œæƒ³è¦ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼ŒåŠ å…¥å‚æ•°model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.6415705680847168}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('ä½ å¤ªå¥½äº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline()çš„ç»†èŠ‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AutoTokenizerï¼šç”¨æ¥å¾—åˆ°ä¸æ¨¡å‹åŒ¹é…çš„åˆ†è¯å™¨\n",
    "* AutoModelForSequenceClassificationï¼šç”¨äºå¥å­çš„åˆ†è¯æ¨¡å‹ï¼Œä¸åŒçš„ä»»åŠ¡ä½¿ç”¨çš„æ¨¡å‹ä¸ä¸€æ ·ï¼Œå…·ä½“å¯ä»¥å‚è€ƒ\n",
    "* from_pretrained() ä¸Šé¢ä¸¤ä¸ªç±»çš„æ–¹æ³•ï¼Œå–å‡ºç›®æ ‡æ¨¡å‹çš„åå­—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœä½ æ²¡æœ‰çœ‹åˆ°å’Œä½ ç°åœ¨çš„æ•°æ®é›†çš„dataç›¸ä¼¼çš„pre-train modelæ—¶ï¼Œä½ å¯ä»¥æ‹¿è‡ªå·±çš„æ•°æ®å†è®­ç»ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.6415705680847168}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('ä½ å¤ªå¥½äº†')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under the hood: pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTORCH CODE\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "## TENSORFLOW CODE\n",
    "# from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "# model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "# tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1855, 100, 100, 100, 100, 100, 1974, 100, 100, 1916, 1810, 100, 100, 1636, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"æˆ‘å–œæ¬¢å¸å¸æœå†»ã€‚\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“è¦ä¼ å…¥å¤šä¸ªå¥å­çš„æ—¶å€™ï¼Œåšæˆä¸€ä¸ªbatchï¼ŒpadæˆåŒæ ·çš„é•¿åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['æˆ‘æ˜¯ç»ä¸–å¥½ç”·äººã€‚','ä¸äºŒå­æ˜¯æˆ‘çš„å¥³ç¥ã€‚']\n",
    "pt_batch = tokenizer(lines, \n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:[[101, 1855, 100, 100, 100, 1916, 100, 100, 1636, 102, 0], [101, 100, 100, 1916, 1810, 100, 100, 100, 1979, 1636, 102]]\n",
      "attention_mask:[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in pt_batch.items():\n",
    "    print(f\"{key}:{value.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.4589, -1.2317],\n",
      "        [ 1.3499, -1.1157]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "pt_outputs = pt_model(**pt_batch)  # æ³¨æ„è¦æ‰“åŒ…\n",
    "print(pt_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯ä»¥çœ‹åˆ°æ²¡æœ‰pipelineçš„æ¨¡å‹æœ€åå¾—åˆ°çš„ç»“æœæ˜¯åœ¨activation functionä¹‹å‰çš„ç»“æœï¼Œå› ä¸ºæ¿€æ´»å‡½æ•°é€šå¸¸å’Œlossæœ‰å…³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9365, 0.0635],\n",
      "        [0.9217, 0.0783]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits,dim=-1)  # softmaxçš„dimæœ‰ä»€ä¹ˆå½±å“å—\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(1.4189, grad_fn=<NllLossBackward>), logits=tensor([[ 1.4589, -1.2317],\n",
      "        [ 1.3499, -1.1157]], grad_fn=<AddmmBackward>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "# å½“ä½ æä¾›labelsçš„æ—¶å€™ï¼Œè¾“å‡ºä¼šå¸¦ä¸Šä¸€ä¸ªloss\n",
    "import torch\n",
    "pt_outputs = pt_model(**pt_batch, labels = torch.tensor([1,0]))\n",
    "print(pt_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŒæ—¶transformersæä¾›äº†ä¸€ä¸ªtrainerç±»æ¥å¸®åŠ©ä½ è®­ç»ƒè‡ªå·±çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tunedåçš„æ¨¡å‹å¯ä»¥ä¿å­˜\n",
    "# tokenizer.save_pretrained(save_directory)\n",
    "# model.save_pretrained(save_directory)\n",
    "\n",
    "# ç„¶åä½ å¯ä»¥ç”¨from_pretrained()å–å‡ºfine-tunedåçš„æ¨¡å‹\n",
    "# from transformers import TFAutoModel\n",
    "# tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "# model = TFAutoModel.from_pretrained(save_directory, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŒæ—¶ä½ å¯ä»¥è¦æ±‚æ¨¡å‹è¿”å›æ‰€æœ‰çš„hidden stateså’Œattention weight\n",
    "pt_outputs = pt_model(**pt_batch, output_hidden_states=True, output_attentions=True)\n",
    "all_hidden_states = pt_outputs.hidden_states\n",
    "all_attentions = pt_outputs.attentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è‡ªå®šä¹‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ï¼Œä¸Šé¢ä½¿ç”¨modelæ—¶ï¼Œå‰ç¼€æ˜¯autoï¼Œä¹Ÿå°±æ˜¯æ ¹æ®æ¨¡å‹çš„åå­—è‡ªåŠ¨æ‹¿å‡ºéœ€è¦çš„æ¨¡å‹ï¼Œä¸‹é¢æ˜¯å–æƒ³è¦ç”¨çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b0d6eaccde457aac6d105d5f87dcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d200c97ae643ae89981540881f435e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d0cad714ff45498a74601d99bed56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = pipeline('fill-mask',model = model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'i am a good man.',\n",
       "  'score': 0.20526237785816193,\n",
       "  'token': 2158,\n",
       "  'token_str': 'm a n'},\n",
       " {'sequence': 'i am a good person.',\n",
       "  'score': 0.11671063303947449,\n",
       "  'token': 2711,\n",
       "  'token_str': 'p e r s o n'},\n",
       " {'sequence': 'i am a good guy.',\n",
       "  'score': 0.08655985444784164,\n",
       "  'token': 3124,\n",
       "  'token_str': 'g u y'},\n",
       " {'sequence': 'i am a good girl.',\n",
       "  'score': 0.0763998031616211,\n",
       "  'token': 2611,\n",
       "  'token_str': 'g i r l'},\n",
       " {'sequence': 'i am a good friend.',\n",
       "  'score': 0.04764905199408531,\n",
       "  'token': 2767,\n",
       "  'token_str': 'f r i e n d'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker('i am a good [MASK].')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.ä½ å¯ä»¥ä¿®æ”¹æ¨¡å‹çš„å‚æ•°æ¥å¾—åˆ°æœ€åçš„ç»“æœ,æ­¤æ—¶éœ€è¦æ¨¡å‹çš„configç±»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0143d334e87422887a1ce9d8789381b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b28c7e356db44059e6bbc01d0e58211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8df38b2c13b4ec1bfcb50cf0e65b60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "model_name = 'distilbert-base-uncased'\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=10)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_9', 'score': 0.11321061104536057}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\",model=model,tokenizer=tokenizer)\n",
    "classifier(\"ä¸äºŒå­æ˜¯ç»ä¸–å¥½å¥³äººï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_5', 'score': 0.11135512590408325}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"ç‰›é€¼ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
